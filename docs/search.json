[{"path":"index.html","id":"introduction","chapter":"Introduction","heading":"Introduction","text":"Ce manuel est le matériel des travaux pratiques pour le cours GEOG-F-404 Méthode quantitative en géographie à l’Université Libre de Bruxelles.Il contient 3 chapitres:Régression linéairesRégression linéairesAnalyse en composantes principalesAnalyse en composantes principalesClassificationClassification","code":""},{"path":"régressions.html","id":"régressions","chapter":"1 Régressions","heading":"1 Régressions","text":"données utilisées:immoweb_louer.csvimmoweb_louer.csvcensus_2011_logements.xlscensus_2011_logements.xlscantons_judiciaires_bxl_2018.gpkgcantons_judiciaires_bxl_2018.gpkg","code":""},{"path":"régressions.html","id":"préparation","chapter":"1 Régressions","heading":"1.1 Préparation","text":"Pour manipuler les données utilisera les packages suivants:va utiliser les nouveaux packages suivants:Pour réaliser cet exemple, utilisera les données issues d’un scraping\nde Immoweb des logements à louer pour Bruxelles. Les adresses ont été\ngéocodées avec Phacochr.","code":"\nlibrary(tidyverse)## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n## ✔ dplyr     1.1.4     ✔ readr     2.1.5\n## ✔ forcats   1.0.0     ✔ stringr   1.5.1\n## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n## ✔ purrr     1.0.2     \n## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n## ✖ dplyr::filter() masks stats::filter()\n## ✖ dplyr::lag()    masks stats::lag()\n## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\nlibrary(readxl)\nlibrary(sf)## Linking to GEOS 3.11.2, GDAL 3.8.2, PROJ 9.3.1; sf_use_s2() is TRUE\nlibrary(mapsf)\nlibrary(modelr)\nlibrary(jtools)\nlibrary(huxtable)## \n## Attachement du package : 'huxtable'## L'objet suivant est masqué depuis 'package:dplyr':\n## \n##     add_rownames## L'objet suivant est masqué depuis 'package:ggplot2':\n## \n##     theme_grey\nlibrary(ggstats)\nlibrary(performance)## \n## Attachement du package : 'performance'## Les objets suivants sont masqués depuis 'package:huxtable':\n## \n##     print_html, print_md## Les objets suivants sont masqués depuis 'package:modelr':\n## \n##     mae, mse, rmse\nloyers_data<-read_delim(\"data/immoweb_louer.csv\", delim = \";\")## Rows: 17735 Columns: 9\n## ── Column specification ────────────────────────────────────────────────────────\n## Delimiter: \";\"\n## chr  (4): type, PEB, nb_chambres, cd_sector\n## dbl  (4): surface, loyer, x_31370, y_31370\n## dttm (1): date_request\n## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."},{"path":"régressions.html","id":"analyse-de-régression","chapter":"1 Régressions","heading":"1.2 Analyse de régression","text":"","code":""},{"path":"régressions.html","id":"visualiser-et-supprimer-les-outliers","chapter":"1 Régressions","heading":"1.2.1 Visualiser et supprimer les outliers","text":"peut analyser la relation entre la variable loyer et la variable\nsurface, peut simplement réaliser un graphique avec un geom_point:Pour analyser la relation entre les deux variables, il peut être utile\nde supprimer les valeurs abérantes (outliers). Ceci peut se faire de\nfaçon simple en retirant 1% de chaque côté de la distribution en\nappliquant un filtre et en conservant les loyer par surface supérieur au\nquantile 0.01 et inférieur au quantile 0.99:Pour supprimer les outliers, il est possible également d’utiliser de\nfiltre plus “réfléchi” en analysant les données ou en utilisant des\nméthodes plus complexes :\nhttps://delladata.fr/comment-detecter-les-outliers-avec-r/peut alors revisualiser les données et observe une relation\nbeaucoup plus claire:peut ajouter une droite de régression sur le graphique grâce à\ngeom_smooth:","code":"\nloyers_data %>%\nggplot( aes(surface, loyer)) +\n  geom_point(alpha=0.5,cex=1)## Warning: Removed 2066 rows containing missing values or values outside the scale range\n## (`geom_point()`).\nloyers_data<- loyers_data %>%\n  filter(\n    loyer > quantile(loyer, prob = 0.01, na.rm = TRUE),\n    loyer < quantile(loyer, prob = 0.99, na.rm = TRUE),\n    surface > quantile(surface, prob = 0.01, na.rm = TRUE),\n    surface < quantile(surface, prob = 0.99, na.rm = TRUE))\nloyers_data %>%\n    ggplot( aes(surface, loyer)) +\n    geom_point(alpha=0.3,cex=0.5)\nloyers_data %>%\n  ggplot( aes(surface, loyer)) +\n  geom_point(alpha=0.3,cex=0.5)+\n  geom_smooth(formula = y ~ x, method = \"lm\")"},{"path":"régressions.html","id":"régression-simple","chapter":"1 Régressions","heading":"1.2.2 Régression simple","text":"peut réaliser une analyse de régression grâce à la fonction lm où Y =\naX +b ce traduit par Y ~ X. Dans notre cas, tente d’évaluer le loyer\n(Y) en fonction de la surface (X):Pour afficher un résumé des résultats utilise la fonction summary sur\nl’objet créer par la fonction lm:Notez que l’objet model est un objet list qui contient une série de\nchoses qu’il est possible d’aller chercher grâce au $ :\nmodel1\\(coefficients les coefficients model1\\)residuals les résidus\nmodel1$fitted.values les valeurs préditesDe même il est possible d’aller rechercher des éléments du résultat de\nsummary appliqué sur le modèle: summary(model1)$r.squared le R²","code":"\nmodel1<-lm(loyer ~ surface, data=loyers_data)\nsummary(model1)## \n## Call:\n## lm(formula = loyer ~ surface, data = loyers_data)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -4328.9  -210.7   -50.8   147.6  3883.4 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept) 385.3549     7.0466   54.69   <2e-16 ***\n## surface      11.1933     0.0557  200.97   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 435.8 on 15222 degrees of freedom\n## Multiple R-squared:  0.7263, Adjusted R-squared:  0.7263 \n## F-statistic: 4.039e+04 on 1 and 15222 DF,  p-value: < 2.2e-16"},{"path":"régressions.html","id":"régression-multiple","chapter":"1 Régressions","heading":"1.2.3 Régression multiple","text":"peut décider de rajouter des variables dans le modèle en modifiant la\nformule Y = X1 + X2 + X3 + …","code":"\nmodel2<-lm(loyer ~ surface +  type + PEB + nb_chambres, data=loyers_data)\nsummary(model2)## \n## Call:\n## lm(formula = loyer ~ surface + type + PEB + nb_chambres, data = loyers_data)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -4185.1  -212.7   -38.6   154.0  2892.6 \n## \n## Coefficients:\n##                Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)    408.4328    27.3727  14.921  < 2e-16 ***\n## surface         11.1487     0.1127  98.950  < 2e-16 ***\n## typeHOUSE       21.0105    19.6294   1.070 0.284480    \n## PEBB           102.9783    23.7831   4.330 1.50e-05 ***\n## PEBC            11.3038    22.9773   0.492 0.622762    \n## PEBD           -69.1262    22.7818  -3.034 0.002417 ** \n## PEBE           -82.0685    23.5270  -3.488 0.000488 ***\n## PEBF          -118.1271    25.2917  -4.671 3.04e-06 ***\n## PEBG           -99.2732    24.5295  -4.047 5.22e-05 ***\n## nb_chambres1   -12.0105    19.0896  -0.629 0.529254    \n## nb_chambres2     4.8550    19.6849   0.247 0.805194    \n## nb_chambres3   156.4296    23.2023   6.742 1.64e-11 ***\n## nb_chambres4    79.7030    31.7783   2.508 0.012153 *  \n## nb_chambres5+ -135.7740    42.2787  -3.211 0.001325 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 410.4 on 11090 degrees of freedom\n##   (4120 observations effacées parce que manquantes)\n## Multiple R-squared:  0.7633, Adjusted R-squared:  0.763 \n## F-statistic:  2751 on 13 and 11090 DF,  p-value: < 2.2e-16"},{"path":"régressions.html","id":"régression-polynomiale","chapter":"1 Régressions","heading":"1.2.4 Régression polynomiale","text":"","code":""},{"path":"régressions.html","id":"logarithme","chapter":"1 Régressions","heading":"1.2.4.1 Logarithme","text":"Plutôt que de modéliser loyer en fonction de la surface, pourrait\navoir envie de modéliser le loyer selon le logarithme de la surface.Alors soit créer une nouvelle variable et réaliser la régression:soit indiquer le logarithme directement dans la formule du lmOn peut faire un graphique de la façon suivante:","code":"\nloyers_data$log_surface <- log(loyers_data$surface)\n\nmodel3<- lm(loyer ~ log_surface +  type + PEB + nb_chambres, data=loyers_data)\nsummary(model3)## \n## Call:\n## lm(formula = loyer ~ log_surface + type + PEB + nb_chambres, \n##     data = loyers_data)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3415.2  -263.3   -50.6   200.8  2883.8 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)   -4067.02      67.47 -60.282  < 2e-16 ***\n## log_surface    1320.08      16.31  80.923  < 2e-16 ***\n## typeHOUSE        98.95      21.29   4.649 3.38e-06 ***\n## PEBB             92.62      25.88   3.578 0.000347 ***\n## PEBC             11.21      25.01   0.448 0.653853    \n## PEBD            -56.46      24.79  -2.277 0.022783 *  \n## PEBE            -67.66      25.60  -2.643 0.008226 ** \n## PEBF           -105.00      27.52  -3.816 0.000137 ***\n## PEBG            -72.71      26.68  -2.725 0.006443 ** \n## nb_chambres1   -281.90      21.42 -13.161  < 2e-16 ***\n## nb_chambres2   -458.09      24.36 -18.804  < 2e-16 ***\n## nb_chambres3   -249.66      29.24  -8.538  < 2e-16 ***\n## nb_chambres4   -137.41      37.64  -3.650 0.000263 ***\n## nb_chambres5+   130.42      46.17   2.825 0.004743 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 446.6 on 11090 degrees of freedom\n##   (4120 observations effacées parce que manquantes)\n## Multiple R-squared:  0.7198, Adjusted R-squared:  0.7194 \n## F-statistic:  2191 on 13 and 11090 DF,  p-value: < 2.2e-16\nmodel3<- lm(loyer ~ log(surface) +  type + PEB + nb_chambres, data=loyers_data)\nsummary(model3)## \n## Call:\n## lm(formula = loyer ~ log(surface) + type + PEB + nb_chambres, \n##     data = loyers_data)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3415.2  -263.3   -50.6   200.8  2883.8 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)   -4067.02      67.47 -60.282  < 2e-16 ***\n## log(surface)   1320.08      16.31  80.923  < 2e-16 ***\n## typeHOUSE        98.95      21.29   4.649 3.38e-06 ***\n## PEBB             92.62      25.88   3.578 0.000347 ***\n## PEBC             11.21      25.01   0.448 0.653853    \n## PEBD            -56.46      24.79  -2.277 0.022783 *  \n## PEBE            -67.66      25.60  -2.643 0.008226 ** \n## PEBF           -105.00      27.52  -3.816 0.000137 ***\n## PEBG            -72.71      26.68  -2.725 0.006443 ** \n## nb_chambres1   -281.90      21.42 -13.161  < 2e-16 ***\n## nb_chambres2   -458.09      24.36 -18.804  < 2e-16 ***\n## nb_chambres3   -249.66      29.24  -8.538  < 2e-16 ***\n## nb_chambres4   -137.41      37.64  -3.650 0.000263 ***\n## nb_chambres5+   130.42      46.17   2.825 0.004743 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 446.6 on 11090 degrees of freedom\n##   (4120 observations effacées parce que manquantes)\n## Multiple R-squared:  0.7198, Adjusted R-squared:  0.7194 \n## F-statistic:  2191 on 13 and 11090 DF,  p-value: < 2.2e-16\nloyers_data %>%\n  ggplot( aes(surface, loyer)) +\n  geom_point(alpha=0.3,cex=0.5)+\n  geom_smooth(formula = y ~ log(x), method = \"lm\")"},{"path":"régressions.html","id":"division","chapter":"1 Régressions","heading":"1.2.4.2 Division","text":"peut vouloir modéliser le loyer par surface en fonction de la\nsurface:Le graphique avec le dans le formule:","code":"\nloyers_data <- loyers_data %>%\n  mutate(loyer_surface= loyer/surface,\n         inv_surface= 1/surface)\n\nmodel4<- lm(loyer_surface ~ inv_surface +  type + PEB + nb_chambres, data=loyers_data)\nsummary(model4)## \n## Call:\n## lm(formula = loyer_surface ~ inv_surface + type + PEB + nb_chambres, \n##     data = loyers_data)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -11.2378  -2.1955  -0.4891   1.6736  31.3294 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)     8.3490     0.3133  26.647  < 2e-16 ***\n## inv_surface   513.5564     9.6383  53.283  < 2e-16 ***\n## typeHOUSE       0.3212     0.1522   2.111   0.0348 *  \n## PEBB            0.8469     0.1857   4.561 5.14e-06 ***\n## PEBC           -0.0173     0.1793  -0.097   0.9231    \n## PEBD           -0.7036     0.1776  -3.961 7.51e-05 ***\n## PEBE           -0.9432     0.1835  -5.139 2.80e-07 ***\n## PEBF           -1.1262     0.1973  -5.708 1.17e-08 ***\n## PEBG           -1.3072     0.1915  -6.827 9.11e-12 ***\n## nb_chambres1    0.9402     0.1631   5.765 8.38e-09 ***\n## nb_chambres2    1.8815     0.1948   9.659  < 2e-16 ***\n## nb_chambres3    3.2194     0.2225  14.472  < 2e-16 ***\n## nb_chambres4    3.0069     0.2709  11.099  < 2e-16 ***\n## nb_chambres5+   2.3830     0.3180   7.494 7.17e-14 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 3.204 on 11090 degrees of freedom\n##   (4120 observations effacées parce que manquantes)\n## Multiple R-squared:  0.3567, Adjusted R-squared:  0.356 \n## F-statistic: 473.1 on 13 and 11090 DF,  p-value: < 2.2e-16\nloyers_data %>%\n  ggplot( aes(surface, loyer_surface)) +\n  geom_point(alpha=0.3,cex=0.5)+\n  geom_smooth(formula = y ~ I(1/x), method = \"lm\")"},{"path":"régressions.html","id":"exposants","chapter":"1 Régressions","heading":"1.2.4.3 Exposants","text":"pourrait directement placer ces changements dans la formule mais\nalors il faut utiliser la fonction () qui permet de réaliser ces\nopérations. La fonction ( “come si” / “”) permet d’indiquer qu’il\ns’agit d’une formule et non pas une opération sur un vecteur et le ~\n“est dépendant de”.le graphique, de nouveau il faut bien utiliser dans la formule:","code":"\nmodel5<- lm(loyer~ surface + I(surface^2) +  type + PEB + nb_chambres, data=loyers_data)\nsummary(model5)## \n## Call:\n## lm(formula = loyer ~ surface + I(surface^2) + type + PEB + nb_chambres, \n##     data = loyers_data)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -4072.8  -213.4   -37.2   159.6  2881.1 \n## \n## Coefficients:\n##                 Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)    3.562e+02  2.943e+01  12.105  < 2e-16 ***\n## surface        1.259e+01  3.200e-01  39.332  < 2e-16 ***\n## I(surface^2)  -3.933e-03  8.187e-04  -4.804 1.58e-06 ***\n## typeHOUSE      2.305e+01  1.961e+01   1.175 0.239960    \n## PEBB           9.977e+01  2.377e+01   4.197 2.72e-05 ***\n## PEBC           6.240e+00  2.298e+01   0.272 0.785963    \n## PEBD          -7.414e+01  2.278e+01  -3.254 0.001141 ** \n## PEBE          -8.608e+01  2.352e+01  -3.660 0.000253 ***\n## PEBF          -1.216e+02  2.528e+01  -4.811 1.52e-06 ***\n## PEBG          -1.019e+02  2.451e+01  -4.156 3.27e-05 ***\n## nb_chambres1  -3.119e+01  1.948e+01  -1.601 0.109455    \n## nb_chambres2  -4.329e+01  2.207e+01  -1.961 0.049890 *  \n## nb_chambres3   9.303e+01  2.667e+01   3.488 0.000489 ***\n## nb_chambres4   1.865e+01  3.420e+01   0.545 0.585428    \n## nb_chambres5+ -1.391e+02  4.224e+01  -3.293 0.000993 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 410 on 11089 degrees of freedom\n##   (4120 observations effacées parce que manquantes)\n## Multiple R-squared:  0.7638, Adjusted R-squared:  0.7635 \n## F-statistic:  2561 on 14 and 11089 DF,  p-value: < 2.2e-16\nloyers_data %>%\n  ggplot( aes(surface, loyer)) +\n  geom_point(alpha=0.3,cex=0.5)+\n  geom_smooth(formula = y ~ I(x+x^2), method = \"lm\")"},{"path":"régressions.html","id":"visualisation","chapter":"1 Régressions","heading":"1.2.5 Visualisation","text":"Il existe beaucoup de package pour faciliter la visualisation des\nrésultats. # Par exemple pour visualiser rapidement le résultat de\nplusieurs modèle jtools permet de réaliser un tableau synthétique utile:peut également exporter ce résultat en format pdf de la façon\nsuivante:peut visualiser un forest plot de cette façon grâce au package\nggstats:voir ici pour plus de détails: <\nhttps://cran.r-project.org/web/packages/ggstats/vignettes/ggcoef_model.htm\n>","code":"\nlibrary(jtools)\nexport_summs(model1, model2, model3, model4, model5)\n# export_summs(model1, model2,model3, model4,to.file = \"html\", file.name = \"TP08/tableau_regression.html\")\nlibrary(ggstats)\nggcoef_model(model2)\nggcoef_table(model2)"},{"path":"régressions.html","id":"réaliser-les-tests-des-hypothèses","chapter":"1 Régressions","heading":"1.2.6 Réaliser les tests des hypothèses","text":"La réalisation de modèle de régression s’appuie sur une série\nd’hypothèses qu’il s’agit de vérifier dont: - la linéarité des\nrésidus, - la constance de la variance des résidus, - la faible\ninfluence d’outliers, - la non colinéarité entre les variables\nexplicatives, - la normalité des résidus.< https://easystats.github.io/performance/index.html >","code":"\nlibrary(performance)\n#png(\"TP08/check_model.png\", height= 1000, width=1000)\ncheck_model(model2)\n#dev.off()"},{"path":"régressions.html","id":"analyse-géographique","chapter":"1 Régressions","heading":"1.3 Analyse géographique","text":"","code":""},{"path":"régressions.html","id":"analyse-géographique-simple","chapter":"1 Régressions","heading":"1.3.1 Analyse géographique simple","text":"peut réaliser une carte du loyer moyen par secteur statistique. \ncalculer par secteur statistique le nombre d’annonces et le loyer moyen:charge les secteurs statistiquesOn fait une jointure entre le résultat du calcul précédent et les\nsecteurs statistiquesOn réalise la carte","code":"\nloyer_moyen<-loyers_data%>%\n  group_by(cd_sector) %>%\n  summarise(\n    n=n(),\n    loy_moyen= mean(loyer, na.rm=T)\n  )\nsecteurs_stats<- st_read (\"data/sh_statbel_statistical_sectors_31370_20230101.gpkg\")## Reading layer `secteurs_stats2023' from data source \n##   `C:\\Users\\hugop\\Nextcloud\\git\\book\\data\\sh_statbel_statistical_sectors_31370_20230101.gpkg' \n##   using driver `GPKG'\n## Simple feature collection with 19795 features and 31 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: 21991.63 ymin: 21162.16 xmax: 295167.1 ymax: 244027.2\n## Projected CRS: BD72 / Belgian Lambert 72\nloyer_moyen_sec<-secteurs_stats %>%\n  left_join(loyer_moyen, by=c(\"cd_sector\")) %>%\n  filter(tx_rgn_descr_fr==\"Région de Bruxelles-Capitale\")\nmf_map(x = loyer_moyen_sec,col = \"white\", border = \"grey\")\nmf_map(loyer_moyen_sec,\n       var= c(\"n\", \"loy_moyen\"),\n       type=\"prop_choro\",\n       pal= \"Viridis\",\n       inches=0.14,\n       nbreaks=5,\n       add=T)## 196 'NA' values are not plotted on the map."},{"path":"régressions.html","id":"cartographier-les-résidus","chapter":"1 Régressions","heading":"1.3.2 Cartographier les résidus","text":"Les résidus de la régression se trouve dans l’objet model produit par la\nfonction lm. Néanmoins il s’agit d’un objet list où le valeur manquantes\nont été supprimée. Le package modelr permet de faire facilement la\njointure entre les données de base et les résidus et calculer une\nmoyenne des résidus par secteurs statistiques:joint les résidus au fichier des secteurs statistiquesOn fait une carte des résidus moyen par secteurs statsOn peut alors observer là où le loyer est en moyenne pus élevé ou moins\nélevé que prédit par le modèle.","code":"\nlibrary(modelr)\n\nresid<-loyers_data %>%\n  add_residuals( model2) %>%\n  group_by(cd_sector) %>%\n  summarise(moyenne_residus= mean(resid, na.rm=T),\n            n=n())\nresid_sec<-secteurs_stats%>%\n  left_join(resid, by=c(\"cd_sector\")) %>%\n  filter(tx_rgn_descr_fr==\"Région de Bruxelles-Capitale\")\nmf_map(x = resid_sec,col = \"white\", border = \"grey\")\nmf_map(resid_sec,\n       var= c(\"n\", \"moyenne_residus\"),\n       type=\"prop_choro\",\n       pal= \"Viridis\",\n       inches=0.15,\n       nbreaks=5,\n       add=T)## 196 'NA' values are not plotted on the map."},{"path":"régressions.html","id":"ajouter-une-variable-géographique","chapter":"1 Régressions","heading":"1.3.3 Ajouter une variable géographique","text":"peut ajouter une variable géographique comme l’indice de difficulté\npar secteur statistique de 2010 pour Bruxelles qui une bonne\napproximation de la division sociale de l’espace bruxellois:peut alors ajouter cet indice dans un troisième modèle. Pour réaliser\nceci doit d’abord joindre les donnéesNotez que ici le modèle semble se détériorer puisque le R2 diminue. Ceci\npeut s’expliquer par le fait que le modèle est réaliser sur un nombre\nplus petit de variables.","code":"\nindice <- read_delim(\"data/indice_synthetique.csv\", delim= \";\")## Rows: 7752 Columns: 2\n## ── Column specification ────────────────────────────────────────────────────────\n## Delimiter: \";\"\n## chr (1): Secteur statistique\n## dbl (1): Indice synthétique de difficulté 2010\n## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nindice_sec<-secteurs_stats%>%\n  left_join(indice, by=c(\"cd_sector\"=\"Secteur statistique\")) %>%\n  filter(tx_rgn_descr_fr==\"Région de Bruxelles-Capitale\")\n\nmf_map(indice_sec,\n       var=\"Indice synthétique de difficulté 2010\",\n       type=\"choro\",\n       pal= \"Viridis\",\n       nbreaks=5)\nloyers_data<-loyers_data %>%\n  left_join(indice, by=c(\"cd_sector\"=\"Secteur statistique\"))\n\nmodel6<-lm(loyer ~ surface + PEB+type+nb_chambres +`Indice synthétique de difficulté 2010`, data=loyers_data)\n\nexport_summs(model1, model2, model6)"},{"path":"régressions.html","id":"analyse-de-corrélation-spatiale","chapter":"1 Régressions","heading":"1.3.4 Analyse de corrélation spatiale","text":"peut également réaliser des régressions sur des entités spatiales.\nIci prend les données expulisions et va analyser la correlation\navec la division sociale de l’espace et les cantons pour mesurer un\npossible “effet juge”.importe les données:réalise la jointure spatiale entre les canton et les centroïdes des\nsecteurs statistiques:","code":"\nexpulsions <- read_delim(\"data/expulsions_2018_secteursstat.csv\", delim= \";\")## Rows: 698 Columns: 7\n## ── Column specification ────────────────────────────────────────────────────────\n## Delimiter: \";\"\n## chr (1): ID_SS_bis\n## dbl (6): ID_SS, exp_ais, exp_individu, exp_public, exp_société, exp_total\n## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nindice <- read_delim(\"data/indice_synthetique.csv\", delim= \";\")## Rows: 7752 Columns: 2\n## ── Column specification ────────────────────────────────────────────────────────\n## Delimiter: \";\"\n## chr (1): Secteur statistique\n## dbl (1): Indice synthétique de difficulté 2010\n## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nlogements <- read_excel(\"data/census_2011_logements.xls\")\nsecteurs_stats<- st_read (\"data/sh_statbel_statistical_sectors_31370_20230101.gpkg\")## Reading layer `secteurs_stats2023' from data source \n##   `C:\\Users\\hugop\\Nextcloud\\git\\book\\data\\sh_statbel_statistical_sectors_31370_20230101.gpkg' \n##   using driver `GPKG'\n## Simple feature collection with 19795 features and 31 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: 21991.63 ymin: 21162.16 xmax: 295167.1 ymax: 244027.2\n## Projected CRS: BD72 / Belgian Lambert 72\ncantons<- st_read (\"data/cantons_judiciaires_bxl_2018.gpkg\") %>%\n  st_zm()## Reading layer `cantons_bxl_2018' from data source \n##   `C:\\Users\\hugop\\Nextcloud\\git\\book\\data\\cantons_judiciaires_bxl_2018.gpkg' \n##   using driver `GPKG'\n## Simple feature collection with 20 features and 2 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XYZ\n## Bounding box:  xmin: 141192.7 ymin: 161464.7 xmax: 158003.9 ymax: 178175.9\n## z_range:       zmin: 0 zmax: 0\n## Projected CRS: BD72 / Belgian Lambert 72\ncanton_secteurs<-cantons %>%\n  st_join(st_point_on_surface(secteurs_stats), join= st_intersects) %>%\n  as.data.frame() %>%\n  select(CANTON, cd_sector)## Warning: st_point_on_surface assumes attributes are constant over geometries"},{"path":"régressions.html","id":"analyse-visuelle","chapter":"1 Régressions","heading":"1.3.4.1 Analyse visuelle","text":"peut réaliser une cartographie des trois jeux de données","code":""},{"path":"régressions.html","id":"les-expulsions","chapter":"1 Régressions","heading":"1.3.4.1.1 Les expulsions","text":"","code":"\nsecteurs_stats_epulsions<-secteurs_stats %>%\n  left_join(expulsions,  by=c(\"cd_sector\"=\"ID_SS_bis\")) %>%\n  left_join(logements, by= c(\"cd_sector\"=\"Secteur statistique\")) %>%\n  filter(tx_rgn_descr_fr==\"Région de Bruxelles-Capitale\") %>%\n  mutate(tx_expulsion=100*exp_total /`Logements loués`)\n\nmf_map(x = secteurs_stats_epulsions,col = \"white\", border = \"grey\")\nmf_map(secteurs_stats_epulsions,\n       var=c(\"exp_total\", \"tx_expulsion\"),\n       type=\"prop_choro\",\n       pal= \"Viridis\",\n       inches=0.11,\n       nbreaks=5,\n       add=T)## 26 'NA' values are not plotted on the map.## 140 '0' values are not plotted on the map."},{"path":"régressions.html","id":"les-cantons","chapter":"1 Régressions","heading":"1.3.4.1.2 Les cantons:","text":"","code":"\nsecteurs_stats_cantons<-secteurs_stats %>%\n  left_join(canton_secteurs, by=\"cd_sector\") %>%\n  filter(tx_rgn_descr_fr==\"Région de Bruxelles-Capitale\")\n\nmf_map(secteurs_stats_cantons,\n       var= \"CANTON\",\n       type=\"typo\")"},{"path":"régressions.html","id":"lindice-synthétique-de-difficulté","chapter":"1 Régressions","heading":"1.3.4.1.3 L’indice synthétique de difficulté:","text":"","code":"\nsecteurs_stats_indice<-secteurs_stats %>%\n  left_join(indice, by= c(\"cd_sector\"=\"Secteur statistique\")) %>%\n  filter(tx_rgn_descr_fr==\"Région de Bruxelles-Capitale\")\n\nmf_map(secteurs_stats_indice,\n       var= \"Indice synthétique de difficulté 2010\",\n       type=\"choro\",\n       pal= \"Viridis\")"},{"path":"régressions.html","id":"régression","chapter":"1 Régressions","heading":"1.3.4.2 Régression","text":"réalise les jointures, calcul un taux d’expulsions et ne garde\nque les secteurs statistiques bruxellois qui ont plus de 200 logements\nlouésOn peut analyser le lien entre indice synthétique et le taux\nd’expulsion:Et réaliser une régressionOn peut à nouveau cartographier les résidusOn peut pondéré la régression par le nombre de logements loués. Dans le\ncas où des entités de tailles très différentes cela peut avoir du\nsensOn peut ajouter la variable canton pour mesurer “l’effet juge”","code":"\nsecteurs_stats_expulsions<-secteurs_stats %>%\n  left_join(expulsions, by=c(\"cd_sector\"=\"ID_SS_bis\")) %>%\n  left_join(logements, by= c(\"cd_sector\"=\"Secteur statistique\")) %>%\n  left_join(indice, by= c(\"cd_sector\"=\"Secteur statistique\")) %>%\n  left_join(canton_secteurs,by= c(\"cd_sector\")) %>%\n  mutate(tx_expulsion=100*exp_total /`Logements loués`) %>%\n  filter(tx_rgn_descr_fr==\"Région de Bruxelles-Capitale\") %>%\n  filter (`Logements loués`>200)\nsecteurs_stats_expulsions%>%\n  ggplot( aes(`Indice synthétique de difficulté 2010`, tx_expulsion)) +\n  geom_point(alpha=0.3,cex=0.5)+\n  geom_smooth(formula = y ~ x, method = \"lm\")\nmodel1<-lm(tx_expulsion~ `Indice synthétique de difficulté 2010`,data= secteurs_stats_expulsions )\nsummary(model1)## \n## Call:\n## lm(formula = tx_expulsion ~ `Indice synthétique de difficulté 2010`, \n##     data = secteurs_stats_expulsions)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -1.49704 -0.43992 -0.08241  0.37774  2.96598 \n## \n## Coefficients:\n##                                         Estimate Std. Error t value Pr(>|t|)\n## (Intercept)                              1.15698    0.04469  25.887  < 2e-16\n## `Indice synthétique de difficulté 2010`  0.15447    0.03208   4.815 2.02e-06\n##                                            \n## (Intercept)                             ***\n## `Indice synthétique de difficulté 2010` ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.6788 on 450 degrees of freedom\n## Multiple R-squared:  0.04899,    Adjusted R-squared:  0.04688 \n## F-statistic: 23.18 on 1 and 450 DF,  p-value: 2.018e-06\nsecteurs_stats_expulsions1<-secteurs_stats_expulsions %>%\n  add_residuals( model1)\n\nmf_map(x = filter(secteurs_stats, tx_rgn_descr_fr==\"Région de Bruxelles-Capitale\"),\n       col = \"white\", border = \"grey\")\nmf_map(secteurs_stats_expulsions1,\n       var=c(\"exp_total\", \"resid\"),\n       type=\"prop_choro\",\n       pal= \"Viridis\",\n       inches=0.11,\n       nbreaks=5,\n       add=T)## 11 '0' values are not plotted on the map.\nmodel2<-lm(tx_expulsion~ `Indice synthétique de difficulté 2010`, weights = `Logements loués`,data= secteurs_stats_expulsions )\nsummary(model2)## \n## Call:\n## lm(formula = tx_expulsion ~ `Indice synthétique de difficulté 2010`, \n##     data = secteurs_stats_expulsions, weights = `Logements loués`)\n## \n## Weighted Residuals:\n##      Min       1Q   Median       3Q      Max \n## -110.573   -9.817   -1.243    9.429   63.777 \n## \n## Coefficients:\n##                                         Estimate Std. Error t value Pr(>|t|)\n## (Intercept)                              1.17420    0.04720  24.879  < 2e-16\n## `Indice synthétique de difficulté 2010`  0.10944    0.03095   3.536 0.000448\n##                                            \n## (Intercept)                             ***\n## `Indice synthétique de difficulté 2010` ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 16.14 on 450 degrees of freedom\n## Multiple R-squared:  0.02704,    Adjusted R-squared:  0.02488 \n## F-statistic:  12.5 on 1 and 450 DF,  p-value: 0.000448\nsecteurs_stats_expulsions%>%\n  ggplot( aes(x=`Indice synthétique de difficulté 2010`,y= tx_expulsion)) +\n  geom_point(alpha=0.3, aes( size= `Logements loués` ) )+\n  geom_smooth(formula = y ~ x, method = \"lm\", mapping = aes(weight = `Logements loués`))\nmodel3<-lm(tx_expulsion~ `Indice synthétique de difficulté 2010`+ CANTON,data= secteurs_stats_expulsions )\n\nlibrary(ggstats)\nggcoef_table(model3)"},{"path":"analyse-en-composantes-principales.html","id":"analyse-en-composantes-principales","chapter":"2 Analyse en Composantes Principales","heading":"2 Analyse en Composantes Principales","text":"","code":""},{"path":"analyse-en-composantes-principales.html","id":"objectif","chapter":"2 Analyse en Composantes Principales","heading":"2.1 Objectif:","text":"L’objectif de ce TP est de réaliser une analyse en composante principale sur base de données électorales.","code":""},{"path":"analyse-en-composantes-principales.html","id":"données","chapter":"2 Analyse en Composantes Principales","heading":"2.2 Données:","text":"données des élections présidentielles 2022 par communes : pres2022comm.csv (https://unehistoireduconflitpolitique.fr/telecharger.html)Ce fichier contient les résultats des élections présidentielles de 2022 en format csv. Ces fichiers ont été générés à partir des résultats électoraux disponibles sur le site du Ministère de l’Intérieur et sur data.gouv.fr. J. Cagé et T. Piketty (2023) : Une histoire du conflit politique. Élections et inégalités sociales en France, 1789-2022. Le Seuil.communes: communes-20220101.shp (1)communes: communes-20220101.shp (1)arrondissement municipaux: arrondissements_municipaux-20180711.shp (2)arrondissement municipaux: arrondissements_municipaux-20180711.shp (2)table commune - région : commune2021.csv (3)table commune - région : commune2021.csv (3)revenus par commune : FILO2021_DEC_COM.xlsx (4)revenus par commune : FILO2021_DEC_COM.xlsx (4)population par commune: population_insee_2021.xlsx (5)population par commune: population_insee_2021.xlsx (5)INSEE: https://www.data.gouv.fr/fr/datasets/decoupage-administratif-communal-francais-issu-d-openstreetmap/INSEE: https://www.data.gouv.fr/fr/datasets/decoupage-administratif-communal-francais-issu-d-openstreetmap/INSEE: https://www.insee.fr/fr/information/2560452INSEE: https://www.insee.fr/fr/statistiques/7756855?sommaire=7756859INSEE : https://www.insee.fr/fr/statistiques/7739582?sommaire=7728826Pour ce TP nous utiliserons les packages suivants:De façon maintenant habituelle:Et deux packages développés pour réaliser des ACP et visualiser les résultats:Les objectifs pour réaliser une ACP sont généralement :Débroussailler un large set de données avec plein de variablesDébroussailler un large set de données avec plein de variablesRéaliser un indicateur synthétiqueRéaliser un indicateur synthétiquePréparer à une classificationPréparer à une classificationDans le cas ici, va plutôt réaliser une ACP suivant le premier objectif sur les votes exprimés aux élections en Île de France aux élections présidentielles de 2022. L’objectif sera de voir retrouve des structures dans la géographie de cette élection.","code":"\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(mapsf)\nlibrary(readxl)\nlibrary(remotes) \n#install_version(\"estimability\", \"1.4.1\")\n#install.packages(\"FactoMineR\") \n#install.packages(\"factoextra\")\nlibrary(FactoMineR)\nlibrary(factoextra)## Welcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa"},{"path":"analyse-en-composantes-principales.html","id":"importation-des-données","chapter":"2 Analyse en Composantes Principales","heading":"2.3 Importation des données","text":"","code":""},{"path":"analyse-en-composantes-principales.html","id":"élections-2022","chapter":"2 Analyse en Composantes Principales","heading":"2.3.1 Élections 2022","text":"Importation des données:prend une table pour ne sélectionner que l’Île de France:","code":"\ndata<-read_delim(\"data/France/pres2022comm.csv\", delim=\",\") %>%\n  select(1:19) %>%\n  filter(codecommune!=\"75056\") # %>% # On enlève la communes de Paris## Rows: 34867 Columns: 97\n## ── Column specification ────────────────────────────────────────────────────────\n## Delimiter: \",\"\n## chr  (4): dep, nomdep, codecommune, nomcommune\n## dbl (93): inscrits, votants, exprimes, voixARTHAUD, voixPOUTOU, voixROUSSEL,...\n## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\ncommunes_table<-read_delim(\"data/France/commune2021.csv\")## Rows: 37742 Columns: 12\n## ── Column specification ────────────────────────────────────────────────────────\n## Delimiter: \",\"\n## chr (11): TYPECOM, COM, REG, DEP, CTCD, ARR, NCC, NCCENR, LIBELLE, CAN, COMP...\n## dbl  (1): TNCC\n## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\ndata<-data %>%\n  left_join(communes_table, by=c(\"codecommune\"=\"COM\"))%>%\n  filter(REG==11) %>%\n  select(-c(20:30))"},{"path":"analyse-en-composantes-principales.html","id":"communes","chapter":"2 Analyse en Composantes Principales","heading":"2.3.2 Communes","text":"ne garde que les communes de l’Ile de France:calcul la densité par communes:créé un objet département pour la cartographie:","code":"\ncommunes<- st_read(\"data/France/communes_arrond_ile_de_france.gpkg\") %>%\n  filter(insee!=\"75056\")## Reading layer `communes_arrond_ile_de_france' from data source \n##   `C:\\Users\\hugop\\Nextcloud\\git\\book\\data\\France\\communes_arrond_ile_de_france.gpkg' \n##   using driver `GPKG'\n## Simple feature collection with 1287 features and 4 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: 1.446244 ymin: 48.12015 xmax: 3.559221 ymax: 49.24143\n## Geodetic CRS:  WGS 84\n# On importe les arrondissements de Paris, Lyon et Marseille\narrond_lyon_mars_paris<- st_read(\"data/France/arrondissements_municipaux-20180711-shp/arrondissements_municipaux-20180711.shp\")%>%\n  select(-surf_km2) %>% \n  rename(geom=geometry)## Reading layer `arrondissements_municipaux-20180711' from data source \n##   `C:\\Users\\hugop\\Nextcloud\\git\\book\\data\\France\\arrondissements_municipaux-20180711-shp\\arrondissements_municipaux-20180711.shp' \n##   using driver `ESRI Shapefile'\n## Simple feature collection with 45 features and 4 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: 2.224122 ymin: 43.19714 xmax: 5.532476 ymax: 48.90216\n## Geodetic CRS:  WGS 84\ncommunes<-bind_rows(communes,arrond_lyon_mars_paris) # On joint communes et arrondissements\nrm(arrond_lyon_mars_paris)\ncommunes<-communes %>%\n  left_join(communes_table, by=c(\"insee\"=\"COM\"))%>%\n  filter(REG==11) %>%\n  select(-c(5:15))## Warning in sf_column %in% names(g): Detected an unexpected many-to-many relationship between `x` and `y`.\n## ℹ Row 17 of `x` matches multiple rows in `y`.\n## ℹ Row 31675 of `y` matches multiple rows in `x`.\n## ℹ If a many-to-many relationship is expected, set `relationship =\n##   \"many-to-many\"` to silence this warning.\ncommunes<-communes %>%\n  mutate(surface=as.numeric(st_area(geom))/10000) # On calcul le superficie de chaque communes\ndepartements_Paris<-communes %>%\n  left_join(communes_table, by=c(\"insee\"=\"COM\")) %>%\n  filter(REG==11) %>%\n  group_by(DEP,REG) %>%\n  summarise(geom=st_union(geom))## Warning in sf_column %in% names(g): Detected an unexpected many-to-many relationship between `x` and `y`.\n## ℹ Row 17 of `x` matches multiple rows in `y`.\n## ℹ Row 31675 of `y` matches multiple rows in `x`.\n## ℹ If a many-to-many relationship is expected, set `relationship =\n##   \"many-to-many\"` to silence this warning.## `summarise()` has grouped output by 'DEP'. You can override using the `.groups`\n## argument.\nrm(communes_table)"},{"path":"analyse-en-composantes-principales.html","id":"recodage","chapter":"2 Analyse en Composantes Principales","heading":"2.4 Recodage","text":"Pour réaliser l’ACP il faut d’abord recoder les variables. utilise généralement des variables en proportion:","code":"\ndata<-data %>%\n  mutate(ARTHAUD=voixARTHAUD/exprimes,\n         POUTOU=voixPOUTOU/exprimes,\n         ROUSSEL=voixROUSSEL/exprimes,\n         MELENCHON=voixMELENCHON/exprimes,\n         JADOT=voixJADOT/exprimes,\n         HIDALGO=voixHIDALGO/exprimes,\n         LASSALLE=voixLASSALLE/exprimes,\n         MACRON=voixMACRON/exprimes,\n         PECRESSE=voixPECRESSE/exprimes,\n         ZEMMOUR=voixZEMMOUR/exprimes,\n         DUPONTAIGNAN=voixDUPONTAIGNAN/exprimes,\n         MLEPEN=voixMLEPEN/exprimes)\n\n\n# De façon raccourcie, il est possible de réaliser de la façon suivante:\n\n# - en utilisant des pivot (tidyr) et un group by\n# data<-data %>%\n#   pivot_longer(cols= 8:19,names_to =\"candidat\", values_to = \"voix\" ) %>%\n#   mutate(voix=voix/exprimes) %>%\n#   pivot_wider(values_from = \"voix\", names_from = \"candidat\")\n\n# - de façon encore plus synthétique, en utilisant un across:\n# data<-data %>%\n#  mutate(across(8:19, ~ . /exprimes))"},{"path":"analyse-en-composantes-principales.html","id":"première-visualisation-des-données","chapter":"2 Analyse en Composantes Principales","heading":"2.5 Première visualisation des données","text":"","code":"\ncommunes_voix<-communes %>%\n  left_join(data, by=c(\"insee\"=\"codecommune\"))"},{"path":"analyse-en-composantes-principales.html","id":"une-carte-par-variable","chapter":"2 Analyse en Composantes Principales","heading":"2.5.1 Une carte par variable","text":"peut réaliser une carte pour chaque candidat:","code":"\nfor (i in 12:23) {\n  # mf_export(x = communes_voix ,\n  #           filename =paste0(\"TP09/cartes_candidats/carte_\",names(communes_voix)[i],\".png\" ),\n  #           width = 900)\n  mf_map(x = communes_voix, col = NA, border = \"gray25\", lwd = 0.1)\n  mf_map(x = departements_Paris, col = NA, border = \"gray25\", lwd = 1, add=T)\n  mf_map(communes_voix ,\n         var= c(names(communes_voix)[i], names(communes_voix)[i+12]),\n         #val_max=max(unlist(communes_voix[,11:22])),\n         type=\"prop_choro\",\n         pal=\"Viridis\",\n         inches=0.1,\n         add=T)\n  #dev.off()\n}## 184 '0' values are not plotted on the map.## 101 '0' values are not plotted on the map.## 42 '0' values are not plotted on the map.## 8 '0' values are not plotted on the map.## 97 '0' values are not plotted on the map.## 18 '0' values are not plotted on the map.## 19 '0' values are not plotted on the map.\nrm(i)"},{"path":"analyse-en-composantes-principales.html","id":"matrice-de-corrélation","chapter":"2 Analyse en Composantes Principales","heading":"2.5.2 Matrice de corrélation","text":"peut réaliser une matrice de corrélation:Le package corrplot permet de visualiser cette matrice de corrélation de façon plus intuitive:peut exporter le résultat avec la fonction png de la façon suivante:voit entre autres des corrélations :positives entre :\nle vote pour Hidalgo, Jadot et Macron,\nle vote Pécresse, Zemmour et Macron\npositives entre :le vote pour Hidalgo, Jadot et Macron,le vote pour Hidalgo, Jadot et Macron,le vote Pécresse, Zemmour et Macronle vote Pécresse, Zemmour et Macronnégative entre:\nle vote Marine Le Pen et le vote Jadot-Macron\nle vote Mélanchon et le vote Pecresse-Zemmour\nnégative entre:le vote Marine Le Pen et le vote Jadot-Macronle vote Marine Le Pen et le vote Jadot-Macronle vote Mélanchon et le vote Pecresse-Zemmourle vote Mélanchon et le vote Pecresse-ZemmourTrès peu de corrélation entre les vote Zemmour et Marine Lepene.","code":"\ncor.mat <- round(cor(data[,20:31], use=\"complete.obs\"),2) # round(,2) permet d'arrondir à deux décimale et use=\"complete.obs\" permet d'exclure les NA\ncor.mat##              ARTHAUD POUTOU ROUSSEL MELENCHON JADOT HIDALGO LASSALLE MACRON\n## ARTHAUD         1.00   0.09    0.05      0.05 -0.16   -0.04     0.08  -0.29\n## POUTOU          0.09   1.00    0.14      0.00 -0.06   -0.03     0.10  -0.24\n## ROUSSEL         0.05   0.14    1.00      0.17 -0.01    0.12     0.01  -0.22\n## MELENCHON       0.05   0.00    0.17      1.00 -0.15    0.11    -0.35  -0.29\n## JADOT          -0.16  -0.06   -0.01     -0.15  1.00    0.33    -0.06   0.58\n## HIDALGO        -0.04  -0.03    0.12      0.11  0.33    1.00    -0.07   0.20\n## LASSALLE        0.08   0.10    0.01     -0.35 -0.06   -0.07     1.00  -0.17\n## MACRON         -0.29  -0.24   -0.22     -0.29  0.58    0.20    -0.17   1.00\n## PECRESSE       -0.13  -0.07   -0.26     -0.54  0.06   -0.11     0.08   0.25\n## ZEMMOUR        -0.07  -0.13   -0.27     -0.53  0.10   -0.14     0.14   0.25\n## DUPONTAIGNAN    0.05   0.06    0.09     -0.29 -0.07   -0.11     0.16  -0.16\n## MLEPEN          0.20   0.17    0.03     -0.40 -0.54   -0.31     0.31  -0.68\n##              PECRESSE ZEMMOUR DUPONTAIGNAN MLEPEN\n## ARTHAUD         -0.13   -0.07         0.05   0.20\n## POUTOU          -0.07   -0.13         0.06   0.17\n## ROUSSEL         -0.26   -0.27         0.09   0.03\n## MELENCHON       -0.54   -0.53        -0.29  -0.40\n## JADOT            0.06    0.10        -0.07  -0.54\n## HIDALGO         -0.11   -0.14        -0.11  -0.31\n## LASSALLE         0.08    0.14         0.16   0.31\n## MACRON           0.25    0.25        -0.16  -0.68\n## PECRESSE         1.00    0.32        -0.02  -0.03\n## ZEMMOUR          0.32    1.00        -0.01  -0.03\n## DUPONTAIGNAN    -0.02   -0.01         1.00   0.29\n## MLEPEN          -0.03   -0.03         0.29   1.00\nlibrary(\"corrplot\")## corrplot 0.94 loaded\ncorrplot(cor.mat, tl.col=\"black\")\n#png(file=\"TP09/matrice_correlation.png\", width = 1000, height = 1000)\ncorrplot(cor.mat, tl.col=\"black\")\n#dev.off()\nrm(cor.mat)"},{"path":"analyse-en-composantes-principales.html","id":"réaliser-lacp","chapter":"2 Analyse en Composantes Principales","heading":"2.6 Réaliser l’ACP","text":"","code":""},{"path":"analyse-en-composantes-principales.html","id":"une-acp-non-pondérée","chapter":"2 Analyse en Composantes Principales","heading":"2.6.1 Une ACP non pondérée","text":"L’objet pca est une liste dans lequel se trouve tous les résultats de l’ACP. peut y accéder directement ou utiliser des fonctions préfaites pour visualiser les résultats:","code":"\npca<-PCA(data[,20:31], graph=T, ncp = NULL)\n# name               description\n# 1  \"$eig\"             \"eigenvalues\"\n# 2  \"$var\"             \"results for the variables\"\n# 3  \"$var$coord\"       \"coord. for the variables\"\n# 4  \"$var$cor\"         \"correlations variables - dimensions\"\n# 5  \"$var$cos2\"        \"cos2 for the variables\"\n# 6  \"$var$contrib\"     \"contributions of the variables\"\n# 7  \"$ind\"             \"results for the individuals\"\n# 8  \"$ind$coord\"       \"coord. for the individuals\"\n# 9  \"$ind$cos2\"        \"cos2 for the individuals\"\n# 10 \"$ind$contrib\"     \"contributions of the individuals\"\n# 11 \"$call\"            \"summary statistics\"\n# 12 \"$call$centre\"     \"mean of the variables\"\n# 13 \"$call$ecart.type\" \"standard error of the variables\"\n# 14 \"$call$row.w\"      \"weights for the individuals\"\n# 15 \"$call$col.w\"      \"weights for the variables\""},{"path":"analyse-en-composantes-principales.html","id":"pondérer-le-calcul-de-lacp","chapter":"2 Analyse en Composantes Principales","heading":"2.6.2 Pondérer le calcul de l’ACP","text":"Dans le cas précédent chacuns des individus à le même poid et chaque variable également. peut décider de modifier les poids.Pourtant, il existe de grandes différences entre communes:Si souhaite pondérer les entités peut utiliser “row.w =”:Pour pondérer les variables peut utiliser col.w Attention: pour pondérer, il faut que tous les poids soient >0. Dans le cas présent ça ne pose pas de problème.","code":"\n# mf_export(x = communes_voix ,\n#           filename =paste0(\"TP09/cartes_votes_exprimes.png\" ),\n#           width = 900)\nmf_map(x = communes_voix, col = NA, border = \"gray25\", lwd = 0.1)\nmf_map(x = departements_Paris, col = NA, border = \"gray25\", lwd = 1, add=T)\nmf_map(communes_voix ,\n       var= \"exprimes\",\n       type=\"prop\",\n       inches=0.1,\n       add=T)\n#dev.off()\nrm(communes_voix)\npca<-PCA(data[,20:31], row.w =data$exprimes,ncp = NULL)"},{"path":"analyse-en-composantes-principales.html","id":"visualiser-les-résultats","chapter":"2 Analyse en Composantes Principales","heading":"2.7 Visualiser les résultats","text":"","code":""},{"path":"analyse-en-composantes-principales.html","id":"cercles-de-corrélation","chapter":"2 Analyse en Composantes Principales","heading":"2.7.1 Cercles de corrélation","text":"Ce résultat sont stocker dans l’objet pca:Les cercle de corrélation permettent de visualiser entre les variables et les dimensions produites par l’ACP.peut décider de visualiser d’autres axes en modifiant le paramètre axes:Pour faciliter la lecture, peut inverser un axe en multipliant par -1 (dans notre cas, il est plus intuitif d’avoir la gauche politique à gauche et la droite à droite):Il faut alors aussi le faire sur les coordonnées des individus:peut décider de ne pas afficher toutes les variables (si il y en trop ça devient illisible). Ici, décide d’afficher surtout (en modifiant la tranparance) celles qui ont le plus contribué à la construction de les deux axes (alpha.var=“contrib”) ou celle qui sont le plus prise en compte par les deux axes (alpha.var=“cos2”), soit encore de sélectionner celles qui ont un cos2 supérieur à un seuil (select.var = list(cos2 = 0.75) ) ou les 3 qui contribuent le plus (select.var = list(contrib = 3))):Il est peut aussi être pertinent d’utiliser l’argument repel=T pour utiliser le package repel pour les étiquettes et éviter qu’elle ne se chevauches:","code":"\npca$var$coord##                    Dim.1        Dim.2        Dim.3       Dim.4       Dim.5\n## ARTHAUD       0.75783970  0.193700662  0.053886556 -0.33202051  0.22476966\n## POUTOU        0.70415312  0.004765184  0.418058777 -0.07460159  0.23692366\n## ROUSSEL       0.66687033 -0.124984377  0.299327347  0.62640195  0.14923271\n## MELENCHON     0.74370403 -0.538863968 -0.340415783 -0.02007377 -0.09595007\n## JADOT        -0.45229731 -0.533488252  0.663311687 -0.03924331 -0.01890221\n## HIDALGO      -0.10246245 -0.687312206  0.620349032 -0.17878940 -0.04634065\n## LASSALLE      0.07686699  0.764044366  0.449976355 -0.03134172  0.14026444\n## MACRON       -0.94011924 -0.048504652  0.166318959  0.02380460  0.02352660\n## PECRESSE     -0.88585300  0.321419606 -0.009943942  0.04293183  0.14109764\n## ZEMMOUR      -0.79129943  0.372205374 -0.100007056  0.06375980  0.19413646\n## DUPONTAIGNAN  0.19419953  0.681063286  0.357058840  0.04326915 -0.55375208\n## MLEPEN        0.45088539  0.809295495  0.102917819 -0.06620236  0.04182531\n##                     Dim.6       Dim.7       Dim.8         Dim.9       Dim.10\n## ARTHAUD      -0.270976655  0.38461093 -0.05343325 -0.0045179775 -0.008370156\n## POUTOU        0.499863557  0.02458871 -0.12931404 -0.0007009491  0.015475982\n## ROUSSEL      -0.131302409  0.12543543  0.02976306 -0.0269964797  0.028203308\n## MELENCHON     0.007735581 -0.03917968 -0.02553644  0.1644913917  0.010914950\n## JADOT        -0.069747306  0.01101491 -0.04680005 -0.0019169799 -0.225853682\n## HIDALGO      -0.040984394 -0.01196939  0.24982650  0.0054539159  0.183340122\n## LASSALLE     -0.191952534 -0.29553028 -0.08181916  0.2339225539  0.025984130\n## MACRON       -0.043682377  0.04938810 -0.18414230 -0.1216818436  0.031798367\n## PECRESSE      0.017812438  0.11278338 -0.11425240 -0.0094676328  0.152069481\n## ZEMMOUR       0.158100636  0.20993077  0.27169444  0.1793777244 -0.079291052\n## DUPONTAIGNAN  0.082126654  0.22599626 -0.03151295  0.0577028315  0.017115750\n## MLEPEN       -0.004296971 -0.15138365  0.19561196 -0.2456237780 -0.040599884\n##                     Dim.11       Dim.12\n## ARTHAUD      -0.0140271624 3.282270e-10\n## POUTOU       -0.0156209607 3.891439e-10\n## ROUSSEL      -0.0056358853 1.336890e-09\n## MELENCHON     0.0401760796 2.360485e-08\n## JADOT         0.1036719950 3.831603e-09\n## HIDALGO      -0.0166654983 1.030643e-09\n## LASSALLE     -0.0303200827 9.593980e-10\n## MACRON       -0.1759761971 1.521580e-08\n## PECRESSE      0.2019841257 5.393004e-09\n## ZEMMOUR      -0.0469535055 5.553946e-09\n## DUPONTAIGNAN  0.0000869299 1.563518e-09\n## MLEPEN        0.0428961375 1.323804e-08\ncercle_1_2<-fviz_pca_var(pca,  axes = c(1, 2))+\n  theme_minimal()\ncercle_1_2\n#ggsave(cercle_1_2,filename=\"TP09/cercle_correlation_1_2.png\", width=7, height=7, bg=\"white\")\n#rm(cercle_1_2)\ncercle_1_3<-fviz_pca_var(pca,  axes = c(1, 3))+\n  theme_minimal()\ncercle_1_3\n#ggsave(cercle_1_3,filename=\"TP09/cercle_correlation_1_3.png\", width=7, height=7, bg=\"white\")\n#rm(cercle_1_3)\npca$var$coord[,1]<- -1*pca$var$coord[,1]\n\ncercle_1_2<-fviz_pca_var(pca,  axes = c(1, 2) )+\n  theme_minimal()\ncercle_1_2\n#ggsave(cercle_1_2,filename=\"TP09/cercle_correlation_1_2.png\", width=7, height=7, bg=\"white\")\npca$ind$coord[,1]<- -1* pca$ind$coord[,1]\nfviz_pca_var(pca,  axes = c(1, 2), alpha.var=\"contrib\")+theme_minimal()\nfviz_pca_var(pca,  axes = c(1, 2), alpha.var=\"cos2\")+ theme_minimal()\nfviz_pca_var(pca,  axes = c(1, 2), select.var = list(cos2 = 0.75))+ theme_minimal()\nfviz_pca_var(pca,  axes = c(1, 2), select.var = list(contrib = 3))+ theme_minimal()\nfviz_pca_var(pca,  axes = c(1, 2), repel=T )+  theme_minimal()"},{"path":"analyse-en-composantes-principales.html","id":"contributions-de-chaque-variables","chapter":"2 Analyse en Composantes Principales","heading":"2.7.2 Contributions de chaque variables","text":"La contribution de chaque variable à la construction de chacune de dimension:peut également afficher de façon graphique avec fviz_contrib:","code":"\npca$var$contrib##                   Dim.1        Dim.2        Dim.3       Dim.4       Dim.5\n## ARTHAUD      11.9038406 1.231246e+00  0.183052896 19.83392132  9.58930308\n## POUTOU       10.2770061 7.451467e-04 11.017687192  1.00132471 10.65438844\n## ROUSSEL       9.2175433 5.126181e-01  5.648180142 70.59679126  4.22707266\n## MELENCHON    11.4639072 9.528856e+00  7.305250657  0.07249975  1.74743980\n## JADOT         4.2401420 9.339684e+00 27.736460944  0.27708309  0.06781672\n## HIDALGO       0.2176015 1.550210e+01 24.259841866  5.75125091  0.40760167\n## LASSALLE      0.1224650 1.915665e+01 12.764245064  0.17673574  3.73427942\n## MACRON       18.3188531 7.720568e-02  1.743810408  0.10195308  0.10505823\n## PECRESSE     16.2650617 3.390215e+00  0.006233513  0.33161753  3.77877609\n## ZEMMOUR      12.9781893 4.546192e+00  0.630488306  0.73142974  7.15362007\n## DUPONTAIGNAN  0.7816796 1.522150e+01  8.037025154  0.33684917 58.20260409\n## MLEPEN        4.2137107 2.149298e+01  0.667723858  0.78854370  0.33203971\n##                     Dim.6       Dim.7      Dim.8        Dim.9      Dim.10\n## ARTHAUD      17.567987257 38.26088046  1.1309610 1.056017e-02  0.05892929\n## POUTOU       59.780728472  0.15638066  6.6239329 2.541885e-04  0.20145614\n## ROUSSEL       4.124807104  4.06960429  0.3508970 3.770484e-01  0.66905864\n## MELENCHON     0.014316739  0.39703930  0.2583124 1.399810e+01  0.10020919\n## JADOT         1.163893177  0.03138149  0.8675954 1.901157e-03 42.90604037\n## HIDALGO       0.401878970  0.03705574 24.7230208 1.538862e-02 28.27347030\n## LASSALLE      8.815479728 22.58997116  2.6517620 2.830917e+01  0.56791122\n## MACRON        0.456531526  0.63089386 13.4317208 7.660100e+00  0.85049882\n## PECRESSE      0.075911050  3.29004564  5.1707694 4.637305e-02 19.45128139\n## ZEMMOUR       5.980334606 11.39892589 29.2405834 1.664638e+01  5.28825575\n## DUPONTAIGNAN  1.613713804 13.21034744  0.3933712 1.722571e+00  0.24640866\n## MLEPEN        0.004417566  5.92747407 15.1570737 3.121215e+01  1.38648022\n##                    Dim.11      Dim.12\n## ARTHAUD      2.190093e-01  0.01030897\n## POUTOU       2.716054e-01  0.01449063\n## ROUSSEL      3.535471e-02  0.17102445\n## MELENCHON    1.796628e+00 53.31743705\n## JADOT        1.196316e+01  1.40484268\n## HIDALGO      3.091431e-01  0.10164445\n## LASSALLE     1.023255e+00  0.08807739\n## MACRON       3.446917e+01 22.15420622\n## PECRESSE     4.541062e+01  2.78309654\n## ZEMMOUR      2.453912e+00  2.95168558\n## DUPONTAIGNAN 8.411265e-06  0.23392274\n## MLEPEN       2.048139e+00 16.76926331\nfviz_contrib(pca, choice = \"var\", axes = 1, top = 10)\nfviz_contrib(pca, choice = \"var\", axes = 2, top = 10)"},{"path":"analyse-en-composantes-principales.html","id":"valeurs-propres-et-de-la-variance-expliquée","chapter":"2 Analyse en Composantes Principales","heading":"2.7.3 Valeurs propres et % de la variance expliquée","text":"Pour afficher les valeurs propres (eigen value) et le pourcentage de variance expliquée, peut simplement afficher le tableau compris dans l’objet pcaOn peut faire un graphique de la variance expliquées:Ces informations sont utiles pour nous aider à décider combien de composante retenir. Généralement, s’arrange avec ces règles non-strictes: - eigenvalue > 1 - variance cumulée > 70% - gain faible d’une composante supplémentaire (ajouter une dimension supplémentaire ne permet pas de gagner beaucoup en variance expliquée)","code":"\npca$eig##           eigenvalue percentage of variance cumulative percentage of variance\n## comp 1  4.824670e+00           4.020558e+01                          40.20558\n## comp 2  3.047316e+00           2.539430e+01                          65.59988\n## comp 3  1.586296e+00           1.321913e+01                          78.81902\n## comp 4  5.558034e-01           4.631695e+00                          83.45071\n## comp 5  5.268516e-01           4.390430e+00                          87.84114\n## comp 6  4.179668e-01           3.483056e+00                          91.32420\n## comp 7  3.866235e-01           3.221863e+00                          94.54606\n## comp 8  2.524500e-01           2.103750e+00                          96.64981\n## comp 9  1.932934e-01           1.610779e+00                          98.26059\n## comp 10 1.188874e-01           9.907285e-01                          99.25132\n## comp 11 8.984151e-02           7.486793e-01                         100.00000\n## comp 12 1.045041e-15           8.708673e-15                         100.00000\nfviz_screeplot(pca, ncp=10)"},{"path":"analyse-en-composantes-principales.html","id":"carte-de-scores","chapter":"2 Analyse en Composantes Principales","heading":"2.7.4 Carte de scores","text":"Chaque individus est reprojeter sur les nouvelles dimensions. Leurs scores sont stocké dans l’objet pca:peut souhaiter les visualiser dans un graphique à deux dimensions:Forcément cela à du sens que si peu d’individus. Si les individus sont des entités géographiques, peut souhaiter en faire des cartes.peut récupérer les score de chaque individus en collant avec bind_rows les coordonnées avec le set de données initiale. doit utiliser ici bind_rows plutôt qu’une jointure (left_join, right_join) parce que l’agorythme de FactoMineR ne conserve pas d’ID lors de la réalisation de l’ACP mais il conserve bien l’ordre des lignes mise en entrée:réalise une boucle pour visualiser les 3 premières dimensions en faisant d’abord la jointure entre nos résultats et l’objet commune:","code":"\nhead(pca$ind$coord)##      Dim.1      Dim.2       Dim.3        Dim.4       Dim.5      Dim.6\n## 1 3.067555 -1.7114152  0.08150264 -0.185735850 -0.41247012 -0.1498315\n## 2 2.511828 -2.7064534  0.70245008 -0.193923389 -0.70891924 -0.4567220\n## 3 2.031107 -3.0966114  1.07311078 -0.404287195 -0.18691460 -0.5270521\n## 4 2.201343 -2.4124210  1.18680228 -0.001301227 -0.20907736  0.2881203\n## 5 1.991101 -2.2577563  1.02941720 -0.014047196 -0.02204558 -0.1995434\n## 6 3.955340 -0.8826657 -0.20675170  0.106337247  0.01854102 -0.1812643\n##         Dim.7       Dim.8      Dim.9      Dim.10      Dim.11        Dim.12\n## 1 -0.31386218  0.51897558 -0.4392267  0.16799431 -0.45550607 -2.122990e-09\n## 2 -0.53505432  0.36256495 -0.6205415 -0.13143940 -0.64944655 -2.768542e-09\n## 3 -0.32566793  0.04083631 -0.7457277 -0.17322620 -0.51307636 -6.765777e-09\n## 4 -0.18494092  0.55795434 -0.3835738  0.18158093 -0.51829968 -1.631543e-09\n## 5 -0.07027549  0.24404548 -0.1594431  0.07828135 -0.03678451 -1.845831e-09\n## 6  0.07415939 -0.23014907 -0.3167121  0.16569411 -0.35174294 -2.268829e-09\nfviz_pca_ind(pca)\ndata_pca<-bind_cols(data,\n                    pca$ind$coord)\ncommunes_pca<-communes %>%\n  inner_join(data_pca, by=c(\"insee\"=\"codecommune\"))\n\n\nfor (i in 1:3){\n  # mf_export(x = communes_pca ,\n  #           filename =paste0(\"TP09/carte_acp_dim\",i,\".png\" ),\n  #           width = 900)\n  mf_map(communes_pca ,\n         var= paste0(\"Dim.\",i),\n         type=\"choro\",\n         pal= \"Viridis\",\n         lwd=0.001)\n  mf_map(x = departements_Paris, col = NA, border = \"gray25\", lwd = 1, add=T)\n  # dev.off()\n}\nrm(i,communes_pca)"},{"path":"analyse-en-composantes-principales.html","id":"ajouter-des-variables-supplémentaires","chapter":"2 Analyse en Composantes Principales","heading":"2.8 Ajouter des variables supplémentaires","text":"Pour aider à l’interprétation des axes, il peut être utile d’importer des nouvelles variables qui ne seront pas utilisées dans l’ACP mais qu’pourra néanmoins utiliser comme repère.","code":""},{"path":"analyse-en-composantes-principales.html","id":"importation-des-données-1","chapter":"2 Analyse en Composantes Principales","heading":"2.8.1 Importation des données","text":"","code":""},{"path":"analyse-en-composantes-principales.html","id":"population","chapter":"2 Analyse en Composantes Principales","heading":"2.8.1.1 Population","text":"importe les données de population:joint avec le fichier spatial des communes et calcul la densité de populationOn peut réaliser une carte de la densité de populationOn enlève transforme l’objet en dataframe et enlève la colonne geom:réalise la jointure avec les données de base:","code":"\npop<-read_excel(\"data/France/population_insee_2021.xlsx\", sheet=\"Communes\") %>%\n  mutate(codecommune=paste0(`Code département`, `Code commune`)) %>%\n  filter(`Code région`==\"11\") # on garde que la France métropolitaine\ncommunes_pop<- communes %>%\n  left_join(pop, by=c(\"insee\"=\"codecommune\")) %>%\n  mutate(densite_ha=`Population totale`/surface) %>%\n  select(insee, densite_ha)\n# mf_export(x = communes_pop ,\n#           filename =paste0(\"TP09/carte_densite.png\" ),\n#           width = 900)\nmf_map(communes_pop ,\n       var= \"densite_ha\",\n       type=\"choro\",\n       pal= \"Viridis\",\n       lwd=0.001)\nmf_map(x = departements_Paris, col = NA, border = \"red\", lwd = 1, add=T)\n#dev.off()\ncommunes_pop_df<-communes_pop %>%\n  as.data.frame() %>%\n  select(-geom)\ndata<-data %>%\n  left_join(communes_pop_df, by=c(\"codecommune\"=\"insee\"))\n\nrm(pop,communes_pop, communes_pop_df)"},{"path":"analyse-en-composantes-principales.html","id":"revenus","chapter":"2 Analyse en Composantes Principales","heading":"2.8.1.2 Revenus","text":"importe les données de revenus, conserve les champ qui nous intéresse et transforme le champ revenu médian en “numeric”:joint avec le fichier spatial des communes et les revenus:peut réaliser une carte de revenu:réalise la jointure avec les données de base:","code":"\nrevenus<-read_excel(\"data/France/FILO2021_DEC_COM.xlsx\", sheet=2) %>%\n  mutate(revenus=as.numeric(revenu_median)) %>%\n  select(CODGEO, revenus)\ncommunes_revenus<- communes %>%\n  left_join(revenus, by=c(\"insee\"=\"CODGEO\"))\n# mf_export(x = communes_revenus ,\n#           filename =paste0(\"TP09/carte_revenus.png\" ),\n#           width = 900)\nmf_map(communes_revenus ,\n       var= \"revenus\",\n       type=\"choro\",\n       pal= \"Viridis\",\n       lwd=0.001)\nmf_map(x = departements_Paris, col = NA, border = \"red\", lwd = 1, add=T)\n#dev.off()\n\nrm(communes_revenus)\ndata<-data %>%\n  left_join(revenus, by=c(\"codecommune\"=\"CODGEO\"))\nrm(revenus)"},{"path":"analyse-en-composantes-principales.html","id":"acp-avec-les-variables-supplémentaires","chapter":"2 Analyse en Composantes Principales","heading":"2.8.2 ACP avec les variables supplémentaires","text":"observe des fortes corrélations entre la première dimension qui dépeind une opposition gauche-droite et la variable de revenus, les revenus élevés étant associés aux communes où le vote de droite est important. La seconde dimension est quant à elle fortement corrélée à la densité de population et permet d’interprétée cette dernière comme l’opposition centre urbain-périphérie","code":"\npca<-PCA(data[,20:33], quanti.sup = 13:14, row.w =data$exprimes, graph=F, ncp = NULL)## Warning in PCA(data[, 20:33], quanti.sup = 13:14, row.w = data$exprimes, :\n## Missing values are imputed by the mean of the variable: you should use the\n## imputePCA function of the missMDA package\ncercle_1_2<-fviz_pca_var(pca,  axes = c(1, 2))+\n  theme_minimal()\ncercle_1_2\n#ggsave(cercle_1_2,filename=\"TP09/cercle_correlation_1_2_revenu_pop.png\", width=7, height=7, bg=\"white\")\nrm(cercle_1_2)\n\n\ncercle_1_3<-fviz_pca_var(pca,  axes = c(1, 3))+\n  theme_minimal()\ncercle_1_3\n#ggsave(cercle_1_3,filename=\"TP09/cercle_correlation_1_3_revenu_pop.png\", width=7, height=7, bg=\"white\")\nrm(cercle_1_3)"},{"path":"analyse-en-composantes-principales.html","id":"aller-plus-loin","chapter":"2 Analyse en Composantes Principales","heading":"2.9 Aller plus loin","text":"Il est possible de faire des ACP sur des données d’enquêtes soit en utilisant les poids comme présenté précédement soit grâce au package :svyprcomp (https://r-survey.r-forge.r-project.org/survey/html/svyprcomp.html)peut vouloir réaliser des légères rotations des axes pour améliorer la lecture des axes: https://stats.stackexchange.com/questions/59213/--compute-varimax-rotated-principal-components--r https://dimension.usherbrooke.ca/pages/87https://sites.google.com/site/rgraphiques/4--stat/machine-learning-biostatistiques-analyse-de-donn%C3%A9es/analyse-en-composantes-principales/la-rotation-varimax","code":""},{"path":"analyse-en-composantes-principales.html","id":"ressources-utilisées","chapter":"2 Analyse en Composantes Principales","heading":"2.10 Ressources utilisées:","text":"http://www.sthda.com/english/wiki/wiki.php?id_contents=7851http://www.sthda.com/english/wiki/wiki.php?id_contents=7851http://factominer.free.fr/index_fr.htmlhttp://factominer.free.fr/index_fr.html","code":""},{"path":"classification.html","id":"classification","chapter":"3 Classification","heading":"3 Classification","text":"","code":""},{"path":"classification.html","id":"objectifs","chapter":"3 Classification","heading":"3.1 Objectifs","text":"Ce tp pour objectif de réaliser une classification ascendante hiérarchique des secteurs statistiques de Bruxelles en utilisant des variables de la structure de la propriété des logements mis en location.","code":""},{"path":"classification.html","id":"préparation-1","chapter":"3 Classification","heading":"3.2 Préparation","text":"De façon maintenant habituelle:Et deux packages développés pour réaliser des ACP et visualiser les résultats:Pour ce TP, utilisera également le packages JLutils:Pour cette classification, utiliser des indicateurs construits à partir des données du cadastre (1 janvier 2015) utilisée dans ma thèse (https://difusion.ulb.ac./vufind/Record/ULB-DIPOT:oai:dipot.ulb.ac.:2013/359086/Holdings)Les variables utilisées sont:cd_sector = code secteur statistiquecd_sector = code secteur statistiqueNB_LOG = nombre de logements totalNB_LOG = nombre de logements totalNB_LOGLOUE_TOT = nombre de logements loués totalNB_LOGLOUE_TOT = nombre de logements loués totalNB_LOCDOM = nombre de logements loués à domicileNB_LOCDOM = nombre de logements loués à domicileprop_occup = proportion de propriétaires occupantsprop_occup = proportion de propriétaires occupantsprop_LOCDOM = proportion de logements loués à domicileprop_LOCDOM = proportion de logements loués à domicileprop_LOC_HBX = proportion de logements loués par des propriétaires habitants en dehors de la région de Bruxellesprop_LOC_HBX = proportion de logements loués par des propriétaires habitants en dehors de la région de Bruxellesdist_200 = proportion de logements loués par des propriétaires domiciliés à moins de 200 mdist_200 = proportion de logements loués par des propriétaires domiciliés à moins de 200 mcinq_plus = proportion de logements loués possédés par des propriétaires possédants 5 logements ou plus à Bruxellescinq_plus = proportion de logements loués possédés par des propriétaires possédants 5 logements ou plus à Bruxellesvingt_plus = proportion de logements loués possédés par des propriétaires possédants 20 logements ou plus à Bruxellesvingt_plus = proportion de logements loués possédés par des propriétaires possédants 20 logements ou plus à Bruxelleslog_sociaux = proportion des logements sociaux parmi les logements louéslog_sociaux = proportion des logements sociaux parmi les logements louésentrep_sprl_sa = proportion des logements possédés par des entreprises privées parmi les logements louésentrep_sprl_sa = proportion des logements possédés par des entreprises privées parmi les logements loués","code":"\nlibrary(tidyverse) # Manipulation des données \nlibrary(sf) # Manipulation des données spatiales\nlibrary(mapsf) # Réalisation de carte\nlibrary(readxl) # Importation de données Excel\nlibrary(kableExtra) # Réalisation de tableau ## \n## Attachement du package : 'kableExtra'## L'objet suivant est masqué depuis 'package:huxtable':\n## \n##     add_footnote## L'objet suivant est masqué depuis 'package:dplyr':\n## \n##     group_rows\nlibrary(FactoMineR)\nlibrary(factoextra)\n#library(devtools)\n#devtools::install_github(\"larmarange/JLutils\")\nlibrary(JLutils)## Registered S3 method overwritten by 'GGally':\n##   method from   \n##   +.gg   ggplot2## \n## Attachement du package : 'JLutils'## Les objets suivants sont masqués depuis 'package:ggstats':\n## \n##     ggsurvey, signif_stars\ncadastre <- read_delim( \"data/cadastre_2015_secteurs.csv\", delim=\";\") %>%\n  filter(NB_LOGLOUE_TOT>=200)## Rows: 724 Columns: 12\n## ── Column specification ────────────────────────────────────────────────────────\n## Delimiter: \";\"\n## chr  (1): cd_sector\n## dbl (11): NB_LOG, NB_LOGLOUE_TOT, NB_LOCDOM, prop_occup, prop_LOCDOM, prop_L...\n## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."},{"path":"classification.html","id":"acp","chapter":"3 Classification","heading":"3.3 ACP","text":"Pour réaliser la classification, va d’abord réaliser une classification. Cela nous permet d’éliminer le bruit.se demande combien de composante garder: les 3 premières représentes 80% de la variance.peut joindre les socres des ACP aux données","code":"\npca<-PCA(cadastre[,6:12], row.w =cadastre$NB_LOGLOUE_TOT,ncp = NULL)fviz_screeplot(pca, ncp=10)\npca$eig\ncadastre<-bind_cols(cadastre,pca$ind$coord)"},{"path":"classification.html","id":"classification-ascendente-hiérarchique","chapter":"3 Classification","heading":"3.4 Classification ascendente hiérarchique","text":"","code":""},{"path":"classification.html","id":"calcul-de-la-classification","chapter":"3 Classification","heading":"3.4.1 Calcul de la classification","text":"extrait les scores des trois premières composantes qu’va utiliser dans la classification:calcul une matrice de distance euclidienne:réalise la classification avec la méthode de Ward:","code":"\nscore<-pca$ind$coord[,1:3]\ndist <- dist(score, method = \"euclidean\")\nhcpc <- hclust(dist, method = \"ward.D\" )"},{"path":"classification.html","id":"choix-du-nombre-de-classe","chapter":"3 Classification","heading":"3.4.2 Choix du nombre de classe","text":"peut réaliser le dendogramme :Ainsi que le graphique d’inertie:Il apparaît ici que le gain pour ajouter une classe supplémentaire diminue fortement après la 5ème classeOn définit donc le paramètre k=5:Il existe une fonction de JLutils qui permet de claculer le nombre de classes “optimale”.","code":"\nplot(hcpc, cex = 0.6, hang = -1)\ninertie <- sort(hcpc$height, decreasing = TRUE)\nplot(inertie[1:20], type = \"s\", xlab = \"Nombre de classes\", ylab = \"Inertie\")\n#png(filename = \"TP10/dendogramme.png\")\nplot(hcpc, cex = 0.6, hang = -1)\nrect.hclust(hcpc , k = 5, border = 2:6)\n#dev.off()\nbest.cutree(hcpc)## [1] 4"},{"path":"classification.html","id":"visualisation-des-résultats","chapter":"3 Classification","heading":"3.5 Visualisation des résultats","text":"","code":""},{"path":"classification.html","id":"extraire-les-groupes","chapter":"3 Classification","heading":"3.5.1 Extraire les groupes","text":"peut alors associer chaque individus (ici les secteurs statistiques) à chaque un groupe:peut alors rapatrier les résultats sur les données de bases:","code":"\nhcpc_indiv <- cutree(hcpc, k = 5)\ncadastre<-cadastre %>%\n  mutate(clust= as.factor(hcpc_indiv))"},{"path":"classification.html","id":"un-graphique-selon-les-groupes","chapter":"3 Classification","heading":"3.5.2 Un graphique selon les groupes","text":"peut réaliser un graphique où place chaque individus (ici les secteurs statistiques) sur les deux dimensions construites lors de l’ACP et colorie les points selon la classe:","code":"\nggplot(data=cadastre,\n       aes(x=Dim.1, y=Dim.2, color=clust)) +\n  geom_point()+\n  theme_minimal()"},{"path":"classification.html","id":"une-carte-des-groupes","chapter":"3 Classification","heading":"3.5.3 Une carte des groupes","text":"importe les secteurs statistiques et garde que les secteurs bruxellois:construit un objet spatial communes pour la cartographie:joint les groupes aux secteurs statistiques:réalise la carte:","code":"\nsecteurs_stats<- st_read (\"data/sh_statbel_statistical_sectors_31370_20230101.gpkg\") %>%\n  filter(tx_rgn_descr_fr==\"Région de Bruxelles-Capitale\")## Reading layer `secteurs_stats2023' from data source \n##   `C:\\Users\\hugop\\Nextcloud\\git\\book\\data\\sh_statbel_statistical_sectors_31370_20230101.gpkg' \n##   using driver `GPKG'\n## Simple feature collection with 19795 features and 31 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: 21991.63 ymin: 21162.16 xmax: 295167.1 ymax: 244027.2\n## Projected CRS: BD72 / Belgian Lambert 72\ncommunes<-secteurs_stats %>%\n  group_by(tx_munty_descr_fr) %>%\n  summarise(geom=st_union(geom))\nsecteurs_stats_cad<- secteurs_stats  %>%\n  left_join(cadastre, by=\"cd_sector\")\n# On peut aussi définir une palette de couleur pour facilité la lecture\npal <- c(\"red\", \"blue\", \"purple\", \"green\", \"orange\")\n\n# mf_export(x = secteurs_stats_cad ,\n#           filename =paste0(\"TP10_typo/carte_typo.png\" ),\n#           width = 900)\nmf_map(x = secteurs_stats, col = NA, border = \"gray25\", lwd = 0.3)\nmf_map(secteurs_stats_cad ,\n       var= c(\"NB_LOGLOUE_TOT\",\"clust\"),\n       type=\"prop_typo\",\n       inches = 0.08,\n       pal= pal,\n       lwd=0.3,\n       add=T)## 225 'NA' values are not plotted on the map.\nmf_map(x = communes, col = NA, border = \"gray25\", lwd = 1, add=T)\n#dev.off()"},{"path":"classification.html","id":"un-tableau-de-statistique-pour-chaque-groupes","chapter":"3 Classification","heading":"3.5.4 Un tableau de statistique pour chaque groupes","text":"réalise des statistiques (ici moyenne pondérée par le nombre de logements loués) par groupes:peut alors donner des noms aux groupesLe package JLutils permet également de colorer le dendogramme:","code":"\ntab<-cadastre %>%\n  group_by(clust) %>%\n  summarise(\n    log_sociaux= weighted.mean(log_sociaux,NB_LOGLOUE_TOT ),\n    entrep_sprl_sa= weighted.mean(entrep_sprl_sa,NB_LOGLOUE_TOT ),\n    prop_LOCDOM= weighted.mean(prop_LOCDOM,NB_LOGLOUE_TOT ),\n    prop_LOC_HBX  = weighted.mean(prop_LOC_HBX,NB_LOGLOUE_TOT ),\n    dist_200 = weighted.mean(dist_200,NB_LOGLOUE_TOT ),\n    cinq_plus= weighted.mean(cinq_plus,NB_LOGLOUE_TOT ),\n    vingt_plus= weighted.mean(vingt_plus,NB_LOGLOUE_TOT ) )\n\n\n# On ajoute une ligne pour la moyenne:\n\nmoyenne_total<-cadastre %>%\n  summarise(\n    log_sociaux= weighted.mean(log_sociaux,NB_LOGLOUE_TOT ),\n    entrep_sprl_sa= weighted.mean(entrep_sprl_sa,NB_LOGLOUE_TOT ),\n    prop_LOCDOM= weighted.mean(prop_LOCDOM,NB_LOGLOUE_TOT ),\n    prop_LOC_HBX  = weighted.mean(prop_LOC_HBX,NB_LOGLOUE_TOT ),\n    dist_200 = weighted.mean(dist_200,NB_LOGLOUE_TOT ),\n    cinq_plus= weighted.mean(cinq_plus,NB_LOGLOUE_TOT ),\n    vingt_plus= weighted.mean(vingt_plus,NB_LOGLOUE_TOT ) )\n\n# On place le résultat dans la ligne donc le numéro est équivalent au nombre de ligne dans le tableau plus une (nrow()+1) pour les colonnes de 2 à 8:\ntab[nrow(tab)+1 ,  2:8]<-moyenne_total\n\n#On multiplie toutes les cellules par 100 et on arrondi avec un 1 chiffre après la virgule:\ntab[,2:8]<-round(100*tab[,2:8],1)\ntab$clust<-as.character(tab$clust)\ntab<- tab %>%\n  mutate(clust=case_when (\n                   clust ==1~\"1. Propriétaires à proximité\",\n                   clust ==2~\"2. Grands propriétaires et entreprises\",\n                   clust ==3~\"3. Type moyen\",\n                   clust ==4~\"4. Propriétaires non-Bruxellois\",\n                   clust ==5~\"5. Logements sociaux\",\n                   is.na(clust)~\"Moyenne\"))\n\nkable(tab)\n# library(JLutils)\nA2Rplot(hcpc, k =5, boxes = T, show.labels = F,col.up = \"gray50\",\n        col.down = pal, main=\"Dendrogramme - 5 classes\")"},{"path":"classification.html","id":"comparaison-avec-une-autre-variable","chapter":"3 Classification","heading":"3.5.5 Comparaison avec une autre variable","text":"importe l’indice synthétique de difficulté:joint l’indice synthétique de difficulté avec les données sur base du secteur statistique:réalise un graphique avec des boxplot:peut en conclure qu’il y un lien entre la division sociale de l’espace et la structure de la propriété des logements loués. Les secteurs du groupe 1 sont plus en difficulté que les autres secteurs, surtout les 3 et 4. Le secteurs centraux (2) ont des indices intermédiaires et certains secteurs de logements sociaux (5) sont très mixtes d’où leur forte dispersion.","code":"\nind_synth <-read_delim(\"data/indice_synthetique.csv\", delim=\";\")## Rows: 7752 Columns: 2\n## ── Column specification ────────────────────────────────────────────────────────\n## Delimiter: \";\"\n## chr (1): Secteur statistique\n## dbl (1): Indice synthétique de difficulté 2010\n## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nindice_sec<-secteurs_stats %>%\n  left_join(ind_synth, by=c(\"cd_sector\"=\"Secteur statistique\")) %>% \n  filter(tx_rgn_descr_fr==\"Région de Bruxelles-Capitale\")\n\nmf_map(indice_sec, \n       var=\"Indice synthétique de difficulté 2010\", \n       type=\"choro\", \n       pal= \"Viridis\", \n       nbreaks=5)\ncadastre<- cadastre %>%\n  left_join(ind_synth,by= c(\"cd_sector\"= \"Secteur statistique\"))\nggplot(data=cadastre,aes(x=clust,\n                           y=`Indice synthétique de difficulté 2010`,\n                           weight=NB_LOGLOUE_TOT,\n                           fill=clust)) +\ngeom_boxplot(fill=pal) +\nlabs(title =\"Relation classification et indice synthétique de difficulté\",\n       x= \" \",\n       y= \"Indice synth. de diff. 2010\")+\ntheme_minimal()"},{"path":"classification.html","id":"ressources-utilisées-1","chapter":"3 Classification","heading":"3.6 Ressources utilisées","text":"https://larmarange.github.io/analyse-R/classification-ascendante-hierarchique.htmlhttps://larmarange.github.io/analyse-R/classification-ascendante-hierarchique.htmlhttp://factominer.free.fr/factomethods/classification-hierarchique-sur-composantes-principales.htmlhttp://factominer.free.fr/factomethods/classification-hierarchique-sur-composantes-principales.htmlhttp://www.sthda.com/english/articles/31-principal-component-methods--r-practical-guide/117-hcpc-hierarchical-clustering--principal-components-essentials/http://www.sthda.com/english/articles/31-principal-component-methods--r-practical-guide/117-hcpc-hierarchical-clustering--principal-components-essentials/","code":""}]
